diff --git a/main.py b/main.py
index 8d41291..8189918 100644
--- a/main.py
+++ b/main.py
@@ -6,6 +6,7 @@ import time
 import warnings
 from enum import Enum
 
+import shutil
 import torch
 import torch.nn as nn
 import torch.nn.parallel
@@ -19,26 +20,28 @@ import torch.utils.data.distributed
 import torchvision.transforms as transforms
 import torchvision.datasets as datasets
 import torchvision.models as models
+from torch.utils.tensorboard import SummaryWriter
+writer=SummaryWriter()
 
 model_names = sorted(name for name in models.__dict__
     if name.islower() and not name.startswith("__")
     and callable(models.__dict__[name]))
 
 parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')
-parser.add_argument('data', metavar='DIR', default='imagenet',
+parser.add_argument('--data', metavar='DIR', default='E:\\OneDrive - USTC\\Python\\Python and Deep learning\\tiny-imagenet-200',
                     help='path to dataset (default: imagenet)')
 parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet18',
                     choices=model_names,
                     help='model architecture: ' +
                         ' | '.join(model_names) +
                         ' (default: resnet18)')
-parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',
+parser.add_argument('-j', '--workers', default=0, type=int, metavar='N',
                     help='number of data loading workers (default: 4)')
 parser.add_argument('--epochs', default=90, type=int, metavar='N',
                     help='number of total epochs to run')
 parser.add_argument('--start-epoch', default=0, type=int, metavar='N',
                     help='manual epoch number (useful on restarts)')
-parser.add_argument('-b', '--batch-size', default=256, type=int,
+parser.add_argument('-b', '--batch-size', default=200, type=int,
                     metavar='N',
                     help='mini-batch size (default: 256), this is the total '
                          'batch size of all GPUs on the current node when '
@@ -52,7 +55,7 @@ parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,
                     dest='weight_decay')
 parser.add_argument('-p', '--print-freq', default=10, type=int,
                     metavar='N', help='print frequency (default: 10)')
-parser.add_argument('--resume', default='', type=str, metavar='PATH',
+parser.add_argument('-r','--resume', default='checkpoint.pth.tar', type=str, metavar='PATH',
                     help='path to latest checkpoint (default: none)')
 parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',
                     help='evaluate model on validation set')
@@ -75,7 +78,6 @@ parser.add_argument('--multiprocessing-distributed', action='store_true',
                          'N processes per node, which has N GPUs. This is the '
                          'fastest way to use PyTorch for either single node or '
                          'multi node data parallel training')
-
 best_acc1 = 0
 
 
@@ -137,7 +139,11 @@ def main_worker(gpu, ngpus_per_node, args):
     else:
         print("=> creating model '{}'".format(args.arch))
         model = models.__dict__[args.arch]()
-
+     # set output dimension as 200
+    model.avgpool=nn.AdaptiveAvgPool2d((1,1))
+    model.fc=nn.Linear(512,200)
+    writer.add_graph(model,torch.rand([1,3,64,64],dtype=torch.float32))
+    # print(model)
     if not torch.cuda.is_available():
         print('using CPU, this will be slow')
     elif args.distributed:
@@ -177,7 +183,7 @@ def main_worker(gpu, ngpus_per_node, args):
                                 weight_decay=args.weight_decay)
     
     """Sets the learning rate to the initial LR decayed by 10 every 30 epochs"""
-    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)
+    scheduler = StepLR(optimizer, step_size=20, gamma=0.1)
     
     # optionally resume from a checkpoint
     if args.resume:
@@ -190,10 +196,10 @@ def main_worker(gpu, ngpus_per_node, args):
                 loc = 'cuda:{}'.format(args.gpu)
                 checkpoint = torch.load(args.resume, map_location=loc)
             args.start_epoch = checkpoint['epoch']
-            best_acc1 = checkpoint['best_acc1']
+            best_acc5 = checkpoint['best_acc5']
             if args.gpu is not None:
                 # best_acc1 may be from a checkpoint from a different GPU
-                best_acc1 = best_acc1.to(args.gpu)
+                best_acc5 = best_acc5.to(args.gpu)
             model.load_state_dict(checkpoint['state_dict'])
             optimizer.load_state_dict(checkpoint['optimizer'])
             scheduler.load_state_dict(checkpoint['scheduler'])
@@ -207,9 +213,10 @@ def main_worker(gpu, ngpus_per_node, args):
     # Data loading code
     traindir = os.path.join(args.data, 'train')
     valdir = os.path.join(args.data, 'val')
-    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
-                                     std=[0.229, 0.224, 0.225])
-
+    # mean,std=getStat(traindir)
+    # normalize = transforms.Normalize(mean=mean,std=std)
+    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])
+   
     train_dataset = datasets.ImageFolder(
         traindir,
         transforms.Compose([
@@ -226,22 +233,44 @@ def main_worker(gpu, ngpus_per_node, args):
 
     train_loader = torch.utils.data.DataLoader(
         train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),
-        num_workers=args.workers, pin_memory=True, sampler=train_sampler)
-
-    val_loader = torch.utils.data.DataLoader(
-        datasets.ImageFolder(valdir, transforms.Compose([
-            transforms.Resize(256),
-            transforms.CenterCrop(224),
-            transforms.ToTensor(),
-            normalize,
-        ])),
-        batch_size=args.batch_size, shuffle=False,
-        num_workers=args.workers, pin_memory=True)
-
+        num_workers=args.workers, pin_memory=False, sampler=train_sampler)
+
+    #get img-class info
+    anno='E:\\OneDrive - USTC\\Python\\Python and Deep learning\\tiny-imagenet-200\\val\\val_annotations.txt'
+    imgs=[]
+    classes=[]
+    with open(anno,'r') as f:
+        while True:
+            con=f.readline()
+            if con:
+                classes.append(con.split('\t')[1])
+                imgs.append(con.split('\t')[0])
+            else:
+                break
+    f.close()
+
+    # change file path
+    images='E:\\OneDrive - USTC\\Python\\Python and Deep learning\\tiny-imagenet-200\\val'
+    if os.path.isdir(os.path.join(images,'images')):
+        for i in range(len(classes)):
+            try:
+                os.mkdir(os.path.join(images,classes[i]))
+            except:
+                pass
+    
+        for i in range(len(imgs)):
+            shutil.copyfile(os.path.join(images,'images',imgs[i]),os.path.join(images,classes[i],imgs[i]))
+        shutil.rmtree(os.path.join(images,'images'))
+    
+    val_dataset=datasets.ImageFolder(valdir, transforms.Compose([transforms.Resize(256),transforms.CenterCrop(224),transforms.ToTensor(),normalize,]))
+    val_loader = torch.utils.data.DataLoader(val_dataset,
+         batch_size=args.batch_size, shuffle=False,
+         num_workers=args.workers, pin_memory=True)
     if args.evaluate:
-        validate(val_loader, model, criterion, args)
-        return
+        validate(val_loader, model, criterion, args,0)
+        return 0
 
+    print('train begin!')
     for epoch in range(args.start_epoch, args.epochs):
         if args.distributed:
             train_sampler.set_epoch(epoch)
@@ -250,14 +279,14 @@ def main_worker(gpu, ngpus_per_node, args):
         train(train_loader, model, criterion, optimizer, epoch, args)
 
         # evaluate on validation set
-        acc1 = validate(val_loader, model, criterion, args)
+        acc5 = validate(val_loader, model, criterion, args,epoch)
         
         scheduler.step()
 
         
         # remember best acc@1 and save checkpoint
-        is_best = acc1 > best_acc1
-        best_acc1 = max(acc1, best_acc1)
+        is_best = acc5 > best_acc1
+        best_acc5 = max(acc5, best_acc1)
 
         if not args.multiprocessing_distributed or (args.multiprocessing_distributed
                 and args.rank % ngpus_per_node == 0):
@@ -265,7 +294,7 @@ def main_worker(gpu, ngpus_per_node, args):
                 'epoch': epoch + 1,
                 'arch': args.arch,
                 'state_dict': model.state_dict(),
-                'best_acc1': best_acc1,
+                'best_acc5': best_acc5,
                 'optimizer' : optimizer.state_dict(),
                 'scheduler' : scheduler.state_dict()
             }, is_best)
@@ -298,7 +327,7 @@ def train(train_loader, model, criterion, optimizer, epoch, args):
         # compute output
         output = model(images)
         loss = criterion(output, target)
-
+        
         # measure accuracy and record loss
         acc1, acc5 = accuracy(output, target, topk=(1, 5))
         losses.update(loss.item(), images.size(0))
@@ -313,12 +342,15 @@ def train(train_loader, model, criterion, optimizer, epoch, args):
         # measure elapsed time
         batch_time.update(time.time() - end)
         end = time.time()
-
+ 
         if i % args.print_freq == 0:
             progress.display(i)
-
-
-def validate(val_loader, model, criterion, args):
+    # add logs
+    # writer.add_image(tag='training images{}'.format(epoch),img_tensor=output,global_step=epoch)
+    writer.add_scalar(tag='train_acc5',scalar_value=acc5[0],global_step=epoch)
+    writer.add_scalar(tag='train_loss',scalar_value=loss.item(),global_step=epoch)
+    
+def validate(val_loader, model, criterion, args,epoch):
     batch_time = AverageMeter('Time', ':6.3f', Summary.NONE)
     losses = AverageMeter('Loss', ':.4e', Summary.NONE)
     top1 = AverageMeter('Acc@1', ':6.2f', Summary.AVERAGE)
@@ -357,8 +389,12 @@ def validate(val_loader, model, criterion, args):
                 progress.display(i)
 
         progress.display_summary()
-
-    return top1.avg
+    # add logs
+    # writer.add_image(tag='val images{}'.format(epoch),img_tensor=output,global_step=epoch)
+    writer.add_scalar(tag='val_acc5',scalar_value=acc5[0],global_step=epoch)
+    writer.add_scalar(tag='val_loss',scalar_value=loss.item(),global_step=epoch)
+   
+    return top5.avg
 
 
 def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):
